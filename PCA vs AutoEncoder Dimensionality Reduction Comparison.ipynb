{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5407c05-90af-4fe6-afe3-1fadd403518a",
   "metadata": {},
   "source": [
    "# Leveraging Unsupervised Learning Models for Clustering and Dimensionality Reduction From TensorFlow Hub and Kaggle\n",
    "\n",
    "Here I explore and evaluate pre-trained models from Kaggle and TensorFlow Hub, considering the tradeoffs between various methods of unsupervised clustering and dimensionality reduction for interfacing with complex, high-dimensional datasets. \n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca5555f2-f0f0-4166-9fd3-1d70ea1ae107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- imports ---\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import perf_counter\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, DBSCAN\n",
    "from sklearn.metrics import (\n",
    "    silhouette_score, davies_bouldin_score, calinski_harabasz_score,\n",
    "    normalized_mutual_info_score, adjusted_rand_score\n",
    ")\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# TF\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc0d227-7439-4330-b60b-5f5716902589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- set your local file paths here ---\n",
    "MNIST_TRAIN_CSV = Path(\"train.csv\")          \n",
    "MALL_CSV        = Path(\"Mall_Customers.csv\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe8be24-3201-47e6-b874-203a3b8d6044",
   "metadata": {},
   "source": [
    "### MNIST Preprocessing (Scaling pixels from 0 - 1, and including a subsequent standard scale on the resulting pixel arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "336437ed-15e1-4222-ad6a-70881d6a9642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST loaded from CSV\n",
      "  X_mnist01 shape (normalized [0,1]): (42000, 784)\n",
      "  X_mnist_scaled shape (standardized): (42000, 784)\n",
      "  y_mnist shape: (42000,)\n",
      "  image shape: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "def load_mnist_from_csv(csv_path: Path):\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Could not find {csv_path}. \"\n",
    "            \"Place Kaggle's MNIST train.csv in your working directory.\"\n",
    "        )\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Expect a 'label' column; everything else are pixels\n",
    "    if \"label\" not in df.columns:\n",
    "        raise ValueError(\"MNIST train.csv must contain a 'label' column.\")\n",
    "    \n",
    "    y = df[\"label\"].astype(int).to_numpy()\n",
    "    X_pixels = df.drop(columns=[\"label\"]).to_numpy(dtype=np.float32)\n",
    "\n",
    "    # Safety checks\n",
    "    if X_pixels.shape[1] != 784:\n",
    "        raise ValueError(f\"Expected 784 pixel columns, found {X_pixels.shape[1]}.\")\n",
    "\n",
    "    # Normalize to [0,1] for AE training; keep a standardized copy for clustering\n",
    "    X01 = X_pixels / 255.0\n",
    "    scaler = StandardScaler()\n",
    "    Xscaled = scaler.fit_transform(X01)\n",
    "\n",
    "    meta = {\n",
    "        \"n_samples\": X01.shape[0],\n",
    "        \"n_features\": X01.shape[1],\n",
    "        \"image_shape\": (28, 28),\n",
    "    }\n",
    "    return X01, Xscaled, y, meta\n",
    "\n",
    "X_mnist01, X_mnist_scaled, y_mnist, mnist_meta = load_mnist_from_csv(MNIST_TRAIN_CSV)\n",
    "mnist_img_shape = mnist_meta[\"image_shape\"]\n",
    "\n",
    "print(\"MNIST loaded from CSV\")\n",
    "print(\"  X_mnist01 shape (normalized [0,1]):\", X_mnist01.shape)\n",
    "print(\"  X_mnist_scaled shape (standardized):\", X_mnist_scaled.shape)\n",
    "print(\"  y_mnist shape:\", y_mnist.shape)\n",
    "print(\"  image shape:\", mnist_img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69211e7b-7ef3-4617-8891-22eb13d502c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAC/CAYAAAAILQRJAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGPlJREFUeJzt3XuwlVXdB/B1AgQBgVAEMRTGSxo3RxFs1FETFbMEpzTNG4qmo+Ld1DHMS2ZmGI43xit4q8RCRUwBZUKkUEedpFAkgRDwgnIRlAPCef96nTfX2m8b9l5n73P25zPjP1/Wep4fuHr2+fnQb9c1NDQ0BAAAACCLr1W6AAAAAGjONN4AAACQkcYbAAAAMtJ4AwAAQEYabwAAAMhI4w0AAAAZabwBAAAgI403AAAAZKTxBgAAgIw03gAAAJCRxrsM1qxZE37+85+HIUOGhM6dO4e6urowbty4SpdFDauvrw+XX3556N69e9h6663DoEGDwtSpUytdFjXI85Fqd8MNN4S6urrQp0+fSpdCDfJ5TTVxHvPSeJfB8uXLw3XXXRfmzp0b+vfvX+lyIAwfPjzccsst4cQTTwy33npraNGiRfjud78bZs6cWenSqDGej1Sz9957L/zyl78M7dq1q3Qp1Cif11QT5zGvuoaGhoZKF9HU1dfXhxUrVoRu3bqFV199Ney7777hgQceCMOHD690adSgl19+OQwaNCjcfPPN4dJLLw0hhLBu3brQp0+fsP3224dZs2ZVuEJqiecj1ez4448PH330Udi4cWNYvnx5mDNnTqVLoob4vKaaOI/5eeNdBq1btw7dunWrdBkQQgjh8ccfDy1atAg/+clPvszatGkTRowYEf7617+GxYsXV7A6ao3nI9VqxowZ4fHHHw9jxoypdCnUKJ/XVBPnMT+NNzQzr7/+eth9991Dhw4d/iMfOHBgCCGEN954owJVAVSPjRs3hpEjR4Yzzjgj9O3bt9LlUKN8XlNNnMf8Wla6AKC8li1bFnbYYYco/99s6dKljV0SQFUZO3ZsWLRoUZg2bVqlS6GG+bymmjiP+XnjDc3M559/Hlq3bh3lbdq0+fLXAWrVxx9/HK6++uowatSo0KVLl0qXQw3zeU01cR7z03hDM7P11luH+vr6KF+3bt2Xvw5Qq372s5+Fzp07h5EjR1a6FGqcz2uqifOYn79qDs3MDjvsEJYsWRLly5YtCyGE0L1798YuCaAqvPPOO+Huu+8OY8aM+Y+/Nrlu3bqwYcOGsHDhwtChQ4fQuXPnClZJrfB5TTVxHvPzxhuamb322ivMmzcvrF69+j/y2bNnf/nrALVoyZIlYdOmTeH8888PvXr1+vKf2bNnh3nz5oVevXqF6667rtJlUiN8XlNNnMf8NN7QzPzwhz8MGzduDHffffeXWX19fXjggQfCoEGDQo8ePSpYHUDl9OnTJ0ycODH6p3fv3mGnnXYKEydODCNGjKh0mdQIn9dUE+cxP3/VvExuv/32sHLlyi//6tqkSZPCe++9F0IIYeTIkaFjx46VLI8aMmjQoHDssceGK6+8Mnz44Ydh1113DePHjw8LFy4M9913X6XLowZ5PlIttttuuzBs2LAo/9/v8k79GuTi85pq4jzmV9fQ0NBQ6SKag549e4ZFixYlf23BggWhZ8+ejVsQNW3dunVh1KhR4eGHHw4rVqwI/fr1C9dff3044ogjKl0aNcjzkWp38MEHh+XLl4c5c+ZUuhRqjM9rqonzmJfGGwAAADLy//EGAACAjDTeAAAAkJHGGwAAADLSeAMAAEBGGm8AAADISOMNAAAAGWm8AQAAIKOWxS6sq6vLWQc1aku/Rt55JAfnkWqypecxBGeSPDwjqSbOI9WkmPPojTcAAABkpPEGAACAjDTeAAAAkJHGGwAAADLSeAMAAEBGGm8AAADISOMNAAAAGWm8AQAAICONNwAAAGSk8QYAAICMNN4AAACQkcYbAAAAMtJ4AwAAQEYabwAAAMhI4w0AAAAZabwBAAAgI403AAAAZKTxBgAAgIw03gAAAJBRy0oXQPlNmzYtyg499NDk2lNPPTXKHnzwwbLXRHE6d+4cZe3bt4+yc889t+hrDho0KMruvPPO5NrVq1dH2XPPPRdlDQ0NRd+f5q9FixbJ/Ne//nWUbdq0KcquuOKK5P6NGzeWVhhAGdTV1SXzbt26Rdk555wTZTvssENy/4gRI0qq64EHHoiya665Jsree++95P7U85jmb3M+sw888MAoGzBgQHL/iy++GGWpn1fnzJnz30pstrzxBgAAgIw03gAAAJCRxhsAAAAy0ngDAABARhpvAAAAyKiuocjxxIUmOlJZ06dPj7L9998/ygpNMBw+fHiUPfTQQyXXVawtnY7dlM7jNttsE2VHHnlkcu3DDz8cZS1blv/LB955551k3qNHjygbP358lN10003J/QsXLiyprkqrhfOYw9Zbb53M165dW9T+tm3bJvN169ZtcU3NQSnfHlDpMzl//vwomzt3bnLtD37wgyhbv3592WvKJXX+Bw8enFw7adKk3OVkVQvPyDZt2kRZ6htgQgjhrrvuyl1OWVxyySXJ/NZbb42ypjTpvBbOY6latWoVZePGjUuuPeGEE6Js8uTJUbZy5crk/uOOOy7KUs/yY489Nrn/2WefTeZNRTHn0RtvAAAAyEjjDQAAABlpvAEAACAjjTcAAABkZLhaE3HVVVcl81GjRkVZapDCY489ltw/YsSIKPvss882s7ot15wGY3Tq1CmZp4bVHXXUUZmryeuDDz5I5kOHDo2yt99+O8pWrVpV9prKoTmdx8ZkuFoeTXm42je+8Y0oKzTUsXv37lG2YsWKsteUy4477hhlEydOTK4dOHBg7nKyak7PyHbt2iXzWbNmRVnfvn1zl1MRI0eOjLI77rijApVsmeZ0HnO58cYbo+zyyy9Prh07dmyUnXPOOUXf6/nnn4+yQw45JMoK/WzQp0+fKFu0aFHR9680w9UAAACgwjTeAAAAkJHGGwAAADLSeAMAAEBGhqtVoWHDhkXZ7373u+TarbbaKsrefPPNKDvwwAOT+z/99NPNK67MmtNgjCFDhiTzZ555ppErqS6pwRypAR7VoDmdx8ZU6nC1c889N5nfddddW1xTc9CUh6ulrF69Opn/4Q9/iLIzzzwzdzllkxqutnjx4uTa1KChv/zlL2WvKZfm9Izceeedk/mCBQsauZLKmTdvXpSNHj06yu6///7k/o0bN5a9ps3RnM5jORxzzDFRluofUkNvQwhhwIABUbZhw4ai758aJnzkkUdGWefOnZP7L7vssihLncdqZbgaAAAAVJjGGwAAADLSeAMAAEBGGm8AAADISOMNAAAAGZlqXmE9evSIsqeeeirK+vXrl9z/ySefRNnpp58eZZMmTdqC6vJrqhMpDzjggCi7/vrrk2sPOuig3OV86YILLoiypUuXRtmll16a3D9o0KCy15SabJ06oyGEMGHChLLff3M01fNYaaVONZ8yZUoyL/RNAbWiuU01HzduXDLv379/lBV6Fq1fv76cJZXF5kw1P/TQQ6Ns+vTpZa8pl6b6jOzatWuUTZs2Lbm2d+/eJd0rNQU6Nbk/hMLfOPNV3bp1S+atW7cuvrAS7Lnnnsm80HTsxtJUz2Op2rRpk8xfeeWVKEud59TPsCGEMGvWrNIKS+jZs2fR9/n444+jbJ999omyavwcCMFUcwAAAKg4jTcAAABkpPEGAACAjDTeAAAAkFHLShdQKwYOHJjM77nnnijr06dP0dcdOXJklFXrILXm5MILL4yycgxRe/XVV6Ns9uzZRe9PDemZM2dOlD377LPJ/Z07d46y1MCzQuc5pV27dlF23HHHJddWergakM+CBQuS+SmnnBJlHTt2TK796KOPylpTOdTX10fZqlWrKlAJhVx88cVRVuoQtRBCeP/996PsrLPOirJSfy47/PDDk/kdd9wRZbvssktJ90p58sknk3lqqOwjjzxS9vvzn1KDdENIn+n7778/yjbn58pSrV69uui1qfq7d+8eZQsXLiylpIryxhsAAAAy0ngDAABARhpvAAAAyEjjDQAAABlpvAEAACAjU80zOPnkk6Ns/PjxybUNDQ1RlpqGOm3atOT+5557bjOrY3PV1dVF2de+Vtp/szrxxBOT+Ycffhhlzz//fEn3Slm7dm3ReWoC+oABA5L7i/1z2WOPPZL59773vSh7+umni7omUN1ee+21SpeQxfLly6Ms9W0SNI5WrVpF2dFHH53lXv/617+iLMc3y0yZMiWZjx49OsquvPLKKOvRo0dJ9999992T+ahRo6JsxowZybWLFy8uqYZa1bZt2yg76aSTit5/4403RtnGjRtLqmlzdOjQIcq6devWaPevNt54AwAAQEYabwAAAMhI4w0AAAAZabwBAAAgI8PVStS1a9cou+yyy0q65pNPPhllp512WknXZMv169cvyoYNG1bSNWfOnJnMq3H4yDXXXBNlb775ZnLthAkTirpm7969k/n3v//9KDNcrfoVGtQyderUKDvssMNyl0OVqq+vr3QJFZd6xk2fPr0ClTRfF1xwQZR985vfLOma69evT+a/+tWvSrpuqcaOHRtlTz31VJRNnDgxuX/fffct6f6poWuFhgGnPve/+OKLku5fC84555woK/Qz1L333htlCxcuLHdJlMAbbwAAAMhI4w0AAAAZabwBAAAgI403AAAAZGS4WpE6deqUzKdMmRJlhYYepHz66adRlhqMQeX06tWrpP2rV6+Osg0bNpR0zUqbNWtWMk/9Xjt06JC7HCqs0OChcePGRZnharUr9XwIofBwvubo2GOPjbKLL764ApU0XzfffHOUNTQ0lHTNV155JZlPnjy5pOvmsHTp0ig75phjkmtTQ9dKHbi22267JfO6urqSrlur2rRpU/Tat99+O8oq/XxNDegtZNWqVVH2+eefl7GayvPGGwAAADLSeAMAAEBGGm8AAADISOMNAAAAGWm8AQAAICNTzYvUrl27ZN6nT5+SrtujR48oS006p3JWrlxZ0v6XX345ylasWFHSNStt2bJlyfyZZ56JsuOPP77o6x5xxBFR1r59++TaNWvWFH1d8mrZMv1R8u1vf7uRK6Ga/e1vf0vmixcvjrJf/OIXybXnnXdelFXjt0QUmnZ9xRVXRNk222wTZX4OqC6pb2hoSlKTzkMIYdiwYVH2+uuvR9n2229fcg0777xzlM2fP7/k6zZ3Q4cOLXrtE088ka+QLVRoyn3Kiy++GGUffPBBOcupOG+8AQAAICONNwAAAGSk8QYAAICMNN4AAACQkeFqCdttt12UTZo0Kbm2rq6uqGsWGiqzfv364gsjqw4dOiTz3//+9yVdd/DgwVFWaFBJashQU/LII49E2eYMV9tpp52irFWrViXVRH6F/h2lBmHBV5155plR9uyzzybX/va3v42yt956q+w1larQMKuOHTtG2X777RdlU6dOLXtN8FWpQanr1q3Lcq9TTjklyq6++uos92qKunbtmsx33XXXKFuwYEFy7fvvv1/Wmsoh1ScV6p1mz56du5yK88YbAAAAMtJ4AwAAQEYabwAAAMhI4w0AAAAZGa6WcPvtt0dZ//79k2sbGhqibNasWVGWGrAVQgj19fWbWR25tGyZ/p9DoUFoxJYsWVLpEoAm5vnnn4+yFStWJNeOGTMmyoYMGVLukko2efLkZP7ZZ581ciWwecaNGxdlhqBVTqrP+Mc//pFcu3bt2tzl/L/atm0bZV26dImy1O8phNr4GdIbbwAAAMhI4w0AAAAZabwBAAAgI403AAAAZKTxBgAAgIxqfqr5dtttF2W77LJL0fs3bNgQZTfddFOUmV5e/VauXJnMH3nkkSg78cQTM1cDwFetWrWq0iUUpdDnyd///vcou+iii6LspZdeSu43FZ3c2rdvn+W6c+fOzXLd5qJ169bJvF27dlHWvXv33OVskY4dO0ZZp06dit7/7rvvlrGa6uSNNwAAAGSk8QYAAICMNN4AAACQkcYbAAAAMqqZ4Wrbb799Mn/00UejbO+9946ydevWJfefffbZUfb0009vZnVUg02bNiXzqVOnRlmpw9UmTJiQzAcPHhxla9asKeleORQaljF+/PiSrjt27NgoKzSkCGi+nnjiiWS+zz77RFnLlvGPMl988UXR90oNKurXr19y7X777RdlRx11VJS1atUqub/Qdb/qyiuvTOajRo0qaj8U4+ijj46ykSNHZrnX448/nuW6zUWhZ9b69esbuZIt953vfCfKtt122ygr9HtaunRp2WuqNt54AwAAQEYabwAAAMhI4w0AAAAZabwBAAAgo5oZrnbMMcck80MOOaSo/S+//HIyf+ihh7a4JpqGJ598MsreeOONKNtrr72KvubAgQOT+QsvvBBll19+eZRNnz696HuVqkuXLlH2m9/8Jrm2b9++RV3z888/T+Y33XRTlDU0NBR1TaD5ePDBB5P5GWecEWWpgWOFhjIeeeSRUbb//vtH2VZbbZXcP2PGjCi75pprouzjjz9O7h82bFiU/fSnP42yWbNmJfdTGal/RyGkP4vffffd3OVstp49eybzzRkMWKxCw9k2Z+BhLSr0zGnXrl0jV/LfHXroocn8zjvvLGr/6NGjk/n8+fO3uKamwhtvAAAAyEjjDQAAABlpvAEAACAjjTcAAABkpPEGAACAjJrlVPMTTjghylLTkgtJTRP98Y9/XFJNNF2rVq2KsvPPPz/K7rrrruT+3r17F32vAQMGRNm1114bZStWrCj6mqtXr46yQtMz27RpE2Xjx4+PsmKnlxfyzDPPJPNFixaVdF0q47bbbqt0CTQzb775ZjKfN29elJ199tlFXzf17Lnkkkui7NVXX03uL5QX65NPPomyQhOz2TKpbx3p379/Sdfcbbfdkvm5554bZanzlMtOO+0UZamfT0499dTk/m233bak+993331RVuhnId9QUj5t27ZN5q1bt46y+vr6ku619957R9nEiROTa9u3bx9lM2fOjLJa/pnBG28AAADISOMNAAAAGWm8AQAAICONNwAAAGTUpIerdezYMZlff/31UbbNNtsUfd3Ro0dH2bJly4ovjGYvNSwide5CSA8fadeuXdH3OuCAA6LstddeK3r/Rx99FGWFBnNsTl2lmDBhQqPch8bRo0ePZF5XV9fIldBcpIZahhDCHnvs0ciVlNfy5csrXUKzd8ghh0TZCy+8EGV77bVXyfdKDTIbPHhwlI0dO7ak+wwfPjyZp4a+derUqaR7pcyZMyeZX3XVVVG2adOmst+/FixZsiSZv/jii1F24IEHJtceccQRUfbUU08VXUNq2N7RRx8dZakhaiGE8NJLL0XZ6aefHmXvv/9+0TU1N954AwAAQEYabwAAAMhI4w0AAAAZabwBAAAgoyY9XG3o0KHJvFevXiVdt0OHDiXtpzY99thjyXzHHXeMstQAv1y6dOnSaPdKDUQ666yzomzy5MmNUQ4V1tDQUOkSgBqzcuXKKEsNP/3jH/9Y8r1atGgRZX379o2yO+64o+R7NZbUILXUwLgQQvjwww9zl1MzNmzYkMwfffTRKCs0XG3MmDFFXffwww9P7j/ppJOiLDVwrdAguNT958+fn1xbq7zxBgAAgIw03gAAAJCRxhsAAAAy0ngDAABARhpvAAAAyKhJTzUvNAFw06ZNUfa1r6X/G8PGjRujbLfddiutMPg/7r333ig77LDDkmuHDBmSu5yyWLt2bTL/0Y9+FGVTpkzJXQ5Ak/Dpp59G2RtvvBFlPXv2zF9MDXniiSei7OSTT06ufeihhzJX0/jeeuutZJ6a9v6nP/0pyurr68teE8X585//HGVr1qxJrk09N0r9FplUT3XRRRcl15bjmwKaO2+8AQAAICONNwAAAGSk8QYAAICMNN4AAACQUV1DQ0NDUQvr6nLXUjb//Oc/o6xly/QcuRtuuCHKxo8fX/aaSCvy+EWa0nlMadOmTTIfPHhwlB1++OFRdt555yX3p/5cUn/Ghf78brvttii79tpro+yLL75I7l+1alUybypq9TyW6qCDDkrm06dPL2r/wQcfnMxnzJixpSU1C1t6HkNwJpuS1ADKJUuWJNeedtppucv5fzWnZ2Shmr7+9a9H2YUXXphcO3To0Cjr27dvSXWlPPjgg8n83//+d5TNnTs3yiZMmJDcX+izvKloTudxc3Tt2jWZ77nnnlF2yimnRNm3vvWt5P6lS5dG2S233BJlM2fO/G8l1qRizqM33gAAAJCRxhsAAAAy0ngDAABARhpvAAAAyEjjDQAAABk1y6nmNB21OpGS6uQ8Uk1MNW9+ttpqqyh75ZVXouz2229P7r/nnnvKXtPm8IykmjiPVBNTzQEAAKDCNN4AAACQkcYbAAAAMtJ4AwAAQEaGq1FRBmNQTZxHqonhalQbz0iqifNINTFcDQAAACpM4w0AAAAZabwBAAAgI403AAAAZKTxBgAAgIw03gAAAJCRxhsAAAAy0ngDAABARhpvAAAAyEjjDQAAABlpvAEAACAjjTcAAABkpPEGAACAjDTeAAAAkJHGGwAAADKqa2hoaKh0EQAAANBceeMNAAAAGWm8AQAAICONNwAAAGSk8QYAAICMNN4AAACQkcYbAAAAMtJ4AwAAQEYabwAAAMhI4w0AAAAZ/Q/JkFU456bn4gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visual check of a few digits\n",
    "n_show = 6\n",
    "fig, axes = plt.subplots(1, n_show, figsize=(10, 2))\n",
    "for i in range(n_show):\n",
    "    img = (X_mnist01[i].reshape(mnist_img_shape))\n",
    "    axes[i].imshow(img, cmap=\"gray\")\n",
    "    axes[i].set_title(int(y_mnist[i]))\n",
    "    axes[i].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c2c8b9-acc4-4dbb-81f9-76abe7663451",
   "metadata": {},
   "source": [
    "Preprocessing of the MNIST dataset includes scaling every image of 28x28 pixels from 0 - 255 to 0 - 1, and then performing a seperate standard scaler step to support downstream clustering approaches like kNN and DBSCAN. Scaling the pixels to [0, 1] is useful for auto encoder input. Following this preprocessing we can observe we have 42,000 unique images now scaled to 28x28 with each pixel value falling between 0 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4542a8-3537-4ba2-ac9d-7f24287733c9",
   "metadata": {},
   "source": [
    "### Mall Customer Preprocessing (OneHoteEncode Gender, imput missing numerical values using the median, and standard scale them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fe3d974-14e4-4306-914e-48e28696c5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mall Customers loaded from CSV\n",
      "  df_cust shape (original selected columns): (200, 4)\n",
      "  X_cust shape (encoded+standardized): (200, 4)\n",
      "  feature names: ['Gender_Male', 'Age', 'Annual Income (k$)', 'Spending Score (1-100)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income (k$)</th>\n",
       "      <th>Spending Score (1-100)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Age  Annual Income (k$)  Spending Score (1-100)\n",
       "0    Male   19                  15                      39\n",
       "1    Male   21                  15                      81\n",
       "2  Female   20                  16                       6\n",
       "3  Female   23                  16                      77\n",
       "4  Female   31                  17                      40"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_mall_customers(csv_path: Path):\n",
    "    if not csv_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Could not find {csv_path}. Download Kaggle's Mall Customers dataset \"\n",
    "            \"and place 'Mall_Customers.csv' in your working directory.\"\n",
    "        )\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Normalize column names to expected ones if necessary\n",
    "    # (Some versions use 'Genre'—rename to 'Gender')\n",
    "    if \"Genre\" in df.columns and \"Gender\" not in df.columns:\n",
    "        df = df.rename(columns={\"Genre\": \"Gender\"})\n",
    "    \n",
    "    required = [\"Gender\", \"Age\", \"Annual Income (k$)\", \"Spending Score (1-100)\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing expected columns: {missing}\")\n",
    "\n",
    "    df_small = df[required].copy()\n",
    "\n",
    "    cat_cols = [\"Gender\"]\n",
    "    num_cols = [\"Age\", \"Annual Income (k$)\", \"Spending Score (1-100)\"]\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\",\n",
    "             OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\"),\n",
    "             cat_cols),\n",
    "            (\"num\",\n",
    "             Pipeline(steps=[\n",
    "                 (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "                 (\"scaler\", StandardScaler()),\n",
    "             ]),\n",
    "             num_cols),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    X = preprocess.fit_transform(df_small)\n",
    "\n",
    "    # Build feature names\n",
    "    ohe = preprocess.named_transformers_[\"cat\"]\n",
    "    cat_names = list(ohe.get_feature_names_out(cat_cols)) if hasattr(ohe, \"get_feature_names_out\") else cat_cols\n",
    "    cust_feature_names = cat_names + num_cols\n",
    "\n",
    "    return df_small, X, cust_feature_names\n",
    "\n",
    "df_cust, X_cust, cust_feature_names = load_mall_customers(MALL_CSV)\n",
    "\n",
    "print(\"Mall Customers loaded from CSV\")\n",
    "print(\"  df_cust shape (original selected columns):\", df_cust.shape)\n",
    "print(\"  X_cust shape (encoded+standardized):\", X_cust.shape)\n",
    "print(\"  feature names:\", cust_feature_names)\n",
    "df_cust.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904f93d0-b10c-4a3b-a854-df9c7282b45f",
   "metadata": {},
   "source": [
    "The gender column has been OneHotEncoded to a binary variable capable of indicating gender, and age/income/score columns have been standard scaled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee24cb4c-94b8-43c4-8f69-fa83617b780c",
   "metadata": {},
   "source": [
    "### PCA for both the MNIST and Mall Customer Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7169103c-f43e-434a-b795-3a32b7a69af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MNIST] PCA- 16D -> explained variance: 0.350\n",
      "[MNIST] PCA- 32D -> explained variance: 0.470\n",
      "[MNIST] PCA- 64D -> explained variance: 0.611\n",
      "[MNIST] PCA-100D -> explained variance: 0.712\n",
      "[CUST ] PCA-  2D -> explained variance: 0.718\n",
      "[CUST ] PCA-  3D -> explained variance: 0.925\n"
     ]
    }
   ],
   "source": [
    "# Choose PCA dimensionalities you want to compare later\n",
    "MNIST_PCA_DIMS = [16, 32, 64, 100]\n",
    "CUST_PCA_DIMS  = [2, 3]   # small tabular set; 2-3 comps are usually enough\n",
    "\n",
    "# Fit PCA on MNIST (X_mnist_scaled)\n",
    "mnist_pca_models = {}\n",
    "mnist_pca_feats  = {}\n",
    "for d in MNIST_PCA_DIMS:\n",
    "    pca = PCA(n_components=d, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_mnist_scaled)\n",
    "    mnist_pca_models[d] = pca\n",
    "    mnist_pca_feats[d]  = X_pca\n",
    "    evr = pca.explained_variance_ratio_.sum()\n",
    "    print(f\"[MNIST] PCA-{d:>3}D -> explained variance: {evr:.3f}\")\n",
    "\n",
    "# Fit PCA on Customers (X_cust)\n",
    "cust_pca_models = {}\n",
    "cust_pca_feats  = {}\n",
    "for d in CUST_PCA_DIMS:\n",
    "    pca = PCA(n_components=d, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_cust)\n",
    "    cust_pca_models[d] = pca\n",
    "    cust_pca_feats[d]  = X_pca\n",
    "    evr = pca.explained_variance_ratio_.sum()\n",
    "    print(f\"[CUST ] PCA-{d:>3}D -> explained variance: {evr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfbe600-3768-4e36-a637-4387ae1ae21f",
   "metadata": {},
   "source": [
    "### Autoendocer for MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aabeecaa-5978-4a39-92e3-f8a2e68f79ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training AE with latent_dim=16 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 10:53:39.101260: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Pro\n",
      "2025-10-01 10:53:39.101348: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 24.00 GB\n",
      "2025-10-01 10:53:39.101359: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 8.00 GB\n",
      "2025-10-01 10:53:39.101414: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-10-01 10:53:39.101441: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2025-10-01 10:53:40.014118: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AE-16D latent shape: (42000, 16) | sample reconstruction MSE (n=1024): 0.11266\n",
      "\n",
      "Training AE with latent_dim=32 ...\n",
      "  AE-32D latent shape: (42000, 32) | sample reconstruction MSE (n=1024): 0.12779\n"
     ]
    }
   ],
   "source": [
    "# --- Tiny dense autoencoder for MNIST (on X_mnist01) ---\n",
    "# Produces latent features you can cluster on (e.g., 16D/32D)\n",
    "def build_dense_autoencoder(input_dim: int, latent_dim: int = 16):\n",
    "    inp = keras.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(512, activation=\"relu\")(inp)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    z = layers.Dense(latent_dim, name=\"latent\")(x)             # linear activation for latent\n",
    "    x = layers.Dense(256, activation=\"relu\")(z)\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    out = layers.Dense(input_dim, activation=\"sigmoid\")(x)     # because inputs are in [0,1]\n",
    "    ae = keras.Model(inp, out, name=f\"AE_{latent_dim}d\")\n",
    "    enc = keras.Model(inp, z, name=f\"Encoder_{latent_dim}d\")\n",
    "    return ae, enc\n",
    "\n",
    "def train_autoencoder(X01, latent_dim=16, max_epochs=50, batch_size=256, verbose=1):\n",
    "    tf.random.set_seed(42)\n",
    "    ae, enc = build_dense_autoencoder(X01.shape[1], latent_dim=latent_dim)\n",
    "    ae.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
    "    es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "    hist = ae.fit(\n",
    "        X01, X01,\n",
    "        epochs=max_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[es],\n",
    "        verbose=verbose\n",
    "    )\n",
    "    Z = enc.predict(X01, batch_size=batch_size, verbose=0)\n",
    "    recon = ae.predict(X01[:1024], batch_size=batch_size, verbose=0)  # quick sample for loss check\n",
    "    recon_mse = np.mean((X01[:1024] - recon) ** 2)\n",
    "    return ae, enc, Z, hist.history, recon_mse\n",
    "\n",
    "# Train two AE variants to compare (16D, 32D)\n",
    "AE_LATENTS = [16, 32]\n",
    "mnist_ae_latents = {}\n",
    "mnist_encoders   = {}\n",
    "mnist_histories  = {}\n",
    "mnist_recon_mse  = {}\n",
    "\n",
    "for ld in AE_LATENTS:\n",
    "    print(f\"\\nTraining AE with latent_dim={ld} ...\")\n",
    "    ae, enc, Z, hist, mse = train_autoencoder(X_mnist01, latent_dim=ld, max_epochs=50, batch_size=256, verbose=0)\n",
    "    mnist_encoders[ld]   = enc\n",
    "    mnist_ae_latents[ld] = Z\n",
    "    mnist_histories[ld]  = hist\n",
    "    mnist_recon_mse[ld]  = mse\n",
    "    print(f\"  AE-{ld}D latent shape: {Z.shape} | sample reconstruction MSE (n=1024): {mse:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4a14b-6557-4219-9cbe-f425dc8d363d",
   "metadata": {},
   "source": [
    "### Autoencoder for Customers dataset (likely overkill relative to PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce282907-5c3a-4c2d-b824-3e6a2b9677e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training small AE for Customers (latent=2) ...\n",
      "WARNING:tensorflow:5 out of the last 173 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x39d5cad40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 174 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x39d5cb010> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Customers AE latent shape: (200, 2) | reconstruction MSE: 0.32294\n"
     ]
    }
   ],
   "source": [
    "#Tiny AE for Customers (tabular) ---\n",
    "# Input is already standardized/OHE as X_cust\n",
    "\n",
    "def build_tabular_autoencoder(input_dim: int, latent_dim: int = 2):\n",
    "    inp = keras.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(16, activation=\"relu\")(inp)\n",
    "    z = layers.Dense(latent_dim, name=\"latent\")(x)\n",
    "    x = layers.Dense(16, activation=\"relu\")(z)\n",
    "    out = layers.Dense(input_dim, activation=None)(x)  # MSE on standardized inputs\n",
    "    ae = keras.Model(inp, out)\n",
    "    enc = keras.Model(inp, z)\n",
    "    return ae, enc\n",
    "\n",
    "def train_tabular_autoencoder(X, latent_dim=2, max_epochs=200, batch_size=64, verbose=0):\n",
    "    tf.random.set_seed(42)\n",
    "    ae, enc = build_tabular_autoencoder(X.shape[1], latent_dim=latent_dim)\n",
    "    ae.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mse\")\n",
    "    es = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True)\n",
    "    hist = ae.fit(\n",
    "        X, X,\n",
    "        epochs=max_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[es],\n",
    "        verbose=verbose\n",
    "    )\n",
    "    Z = enc.predict(X, batch_size=batch_size, verbose=0)\n",
    "    recon = ae.predict(X, batch_size=batch_size, verbose=0)\n",
    "    recon_mse = float(np.mean((X - recon) ** 2))\n",
    "    return ae, enc, Z, hist.history, recon_mse\n",
    "\n",
    "print(\"\\nTraining small AE for Customers (latent=2) ...\")\n",
    "cust_ae, cust_enc, Z_cust, hist_cust, mse_cust = train_tabular_autoencoder(X_cust, latent_dim=2)\n",
    "print(f\"Customers AE latent shape: {Z_cust.shape} | reconstruction MSE: {mse_cust:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b5c62-c6bf-493b-b3f7-0da1b1222c44",
   "metadata": {},
   "source": [
    "### Helper Functions for kMeans and DBSCAN evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97398b96-f3bf-466b-b941-d67ee60b2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- metrics (with sampling) ----------\n",
    "def safe_silhouette(X, labels, sample_size=10000, random_state=42):\n",
    "    labs = np.unique(labels)\n",
    "    if len(labs) <= 1:\n",
    "        return np.nan\n",
    "    try:\n",
    "        # sample-based silhouette (huge speedup)\n",
    "        return silhouette_score(X, labels, metric=\"euclidean\",\n",
    "                                sample_size=min(sample_size, len(X)),\n",
    "                                random_state=random_state)\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def compute_internal_metrics(X, labels, sample_size=10000):\n",
    "    m = {}\n",
    "    m[\"silhouette\"] = safe_silhouette(X, labels, sample_size=sample_size)\n",
    "    try: m[\"davies_bouldin\"] = davies_bouldin_score(X, labels)\n",
    "    except Exception: m[\"davies_bouldin\"] = np.nan\n",
    "    try: m[\"calinski_harabasz\"] = calinski_harabasz_score(X, labels)\n",
    "    except Exception: m[\"calinski_harabasz\"] = np.nan\n",
    "    return m\n",
    "\n",
    "def compute_external_metrics(y_true, labels):\n",
    "    m = {}\n",
    "    try: m[\"NMI\"] = normalized_mutual_info_score(y_true, labels)\n",
    "    except Exception: m[\"NMI\"] = np.nan\n",
    "    try: m[\"ARI\"] = adjusted_rand_score(y_true, labels)\n",
    "    except Exception: m[\"ARI\"] = np.nan\n",
    "    return m\n",
    "\n",
    "def stdz(X):\n",
    "    return StandardScaler().fit_transform(X)\n",
    "\n",
    "# ---------- quick K-Means (to rank spaces fast) ----------\n",
    "def kmeans_silhouette(X, k, sample_size=10000, seed=42):\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=seed)\n",
    "    labels = km.fit_predict(X)\n",
    "    sil = safe_silhouette(X, labels, sample_size=sample_size, random_state=seed)\n",
    "    return sil, labels\n",
    "\n",
    "# ---------- pick top-N spaces by K-Means silhouette ----------\n",
    "def select_spaces_for_dbscan(spaces, k=10, top_n=2):\n",
    "    \"\"\"\n",
    "    spaces: list of (name, X) where X is already scaled\n",
    "    returns: list of (name, X) sorted by KMeans silhouette desc, top_n kept\n",
    "    \"\"\"\n",
    "    scored = []\n",
    "    for name, X in spaces:\n",
    "        sil, _ = kmeans_silhouette(X, k=k, sample_size=8000)\n",
    "        scored.append((sil if sil==sil else -np.inf, name, X))\n",
    "    scored.sort(reverse=True, key=lambda t: t[0])\n",
    "    return [(name, X) for _, name, X in scored[:top_n]]\n",
    "\n",
    "# ---------- fast eps guess from subsample ----------\n",
    "def guess_eps_from_knn(X, min_samples=5, subsample=10000, lo=0.60, hi=0.90, pad=0.10):\n",
    "    \"\"\"\n",
    "    Subsample X, compute kNN (k=min_samples) distances, use quantiles to set eps band.\n",
    "    Returns (eps_lo, eps_hi).\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    idx = np.random.RandomState(42).choice(n, size=min(subsample, n), replace=False)\n",
    "    Xs = X[idx]\n",
    "    # kd_tree/ball_tree are efficient at <= ~50 dims (use euclidean)\n",
    "    nn = NearestNeighbors(n_neighbors=min_samples, algorithm=\"ball_tree\", leaf_size=40, n_jobs=-1)\n",
    "    nn.fit(Xs)\n",
    "    dists, _ = nn.kneighbors(Xs)\n",
    "    kth = dists[:, -1]\n",
    "    q_lo, q_hi = np.quantile(kth, [lo, hi])\n",
    "    return max(1e-6, q_lo*(1-pad)), q_hi*(1+pad)\n",
    "\n",
    "# ---------- single-run or tiny-grid DBSCAN using guessed eps ----------\n",
    "def dbscan_quick(X, min_samples=5, eps=None, eps_band=None):\n",
    "    \"\"\"\n",
    "    If eps is given -> single run. If eps_band=(lo,hi) -> run 3 trials in that band.\n",
    "    \"\"\"\n",
    "    trials = []\n",
    "    if eps is not None:\n",
    "        trials = [eps]\n",
    "    elif eps_band is not None:\n",
    "        lo, hi = eps_band\n",
    "        trials = [lo, (lo+hi)/2.0, hi]\n",
    "    else:\n",
    "        raise ValueError(\"Provide eps or eps_band\")\n",
    "    best = None\n",
    "    for e in trials:\n",
    "        t0 = perf_counter()\n",
    "        labels = DBSCAN(eps=float(e), min_samples=int(min_samples),\n",
    "                        metric='euclidean', algorithm='ball_tree',\n",
    "                        leaf_size=40, n_jobs=-1).fit_predict(X)\n",
    "        dt = perf_counter() - t0\n",
    "        sil = safe_silhouette(X, labels, sample_size=8000)\n",
    "        if (best is None) or ((sil==sil) and (sil > best[\"silhouette\"])):\n",
    "            best = {\"eps\": float(e), \"min_samples\": int(min_samples),\n",
    "                    \"labels\": labels, \"time\": dt, \"silhouette\": sil}\n",
    "    return best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561698cd-8346-4a47-a4b3-5634e2980f2c",
   "metadata": {},
   "source": [
    "### MNIST KMeans and DBSCAN across feature spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "930e73e3-19f0-45c7-a832-b7b0e49111c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN will run on: ['MNIST-AE32-std', 'MNIST-AE16-std', 'MNIST-PCA16-std', 'MNIST-PCA64-std', 'MNIST-raw-std', 'MNIST-PCA32-std', 'MNIST-PCA100-std']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Space</th>\n",
       "      <th>Method</th>\n",
       "      <th>Fit_Time_s</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>davies_bouldin</th>\n",
       "      <th>calinski_harabasz</th>\n",
       "      <th>NMI</th>\n",
       "      <th>ARI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNIST-AE16-std</td>\n",
       "      <td>DBSCAN(eps=0.9041, ms=5)</td>\n",
       "      <td>1.545315</td>\n",
       "      <td>-0.023168</td>\n",
       "      <td>1.899329</td>\n",
       "      <td>59.547901</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNIST-AE16-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>2.852023</td>\n",
       "      <td>0.211665</td>\n",
       "      <td>1.228651</td>\n",
       "      <td>28006.065111</td>\n",
       "      <td>0.173249</td>\n",
       "      <td>0.090348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNIST-AE32-std</td>\n",
       "      <td>DBSCAN(eps=0.2848, ms=5)</td>\n",
       "      <td>0.227037</td>\n",
       "      <td>-0.200674</td>\n",
       "      <td>1.734830</td>\n",
       "      <td>76.923319</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNIST-AE32-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>3.042286</td>\n",
       "      <td>0.343941</td>\n",
       "      <td>0.829484</td>\n",
       "      <td>35895.852292</td>\n",
       "      <td>0.169458</td>\n",
       "      <td>0.124190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNIST-PCA100-std</td>\n",
       "      <td>DBSCAN(eps=9.2670, ms=5)</td>\n",
       "      <td>44.456795</td>\n",
       "      <td>0.371181</td>\n",
       "      <td>3.205959</td>\n",
       "      <td>64.412320</td>\n",
       "      <td>0.006819</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MNIST-PCA100-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>4.451275</td>\n",
       "      <td>-0.009193</td>\n",
       "      <td>3.575616</td>\n",
       "      <td>349.860343</td>\n",
       "      <td>0.314552</td>\n",
       "      <td>0.172776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MNIST-PCA16-std</td>\n",
       "      <td>DBSCAN(eps=2.8653, ms=5)</td>\n",
       "      <td>8.185663</td>\n",
       "      <td>0.428244</td>\n",
       "      <td>2.376834</td>\n",
       "      <td>242.012744</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MNIST-PCA16-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>2.531696</td>\n",
       "      <td>0.104884</td>\n",
       "      <td>2.000510</td>\n",
       "      <td>2300.084894</td>\n",
       "      <td>0.415973</td>\n",
       "      <td>0.291133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MNIST-PCA32-std</td>\n",
       "      <td>DBSCAN(eps=4.8487, ms=5)</td>\n",
       "      <td>16.217685</td>\n",
       "      <td>0.484579</td>\n",
       "      <td>2.341554</td>\n",
       "      <td>158.518645</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MNIST-PCA32-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>3.117630</td>\n",
       "      <td>-0.005042</td>\n",
       "      <td>2.916262</td>\n",
       "      <td>1068.014889</td>\n",
       "      <td>0.380821</td>\n",
       "      <td>0.243943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MNIST-PCA64-std</td>\n",
       "      <td>DBSCAN(eps=7.3711, ms=5)</td>\n",
       "      <td>29.290378</td>\n",
       "      <td>0.375980</td>\n",
       "      <td>3.482298</td>\n",
       "      <td>122.401711</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.000153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MNIST-PCA64-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>4.148160</td>\n",
       "      <td>0.018253</td>\n",
       "      <td>3.571098</td>\n",
       "      <td>518.282279</td>\n",
       "      <td>0.310092</td>\n",
       "      <td>0.143419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MNIST-raw-std</td>\n",
       "      <td>DBSCAN(eps=27.4674, ms=5)</td>\n",
       "      <td>103.270871</td>\n",
       "      <td>0.445458</td>\n",
       "      <td>3.198306</td>\n",
       "      <td>67.918793</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>0.000291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MNIST-raw-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>11.995339</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>3.309745</td>\n",
       "      <td>868.448541</td>\n",
       "      <td>0.429806</td>\n",
       "      <td>0.316979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature_Space                     Method  Fit_Time_s  silhouette  \\\n",
       "0     MNIST-AE16-std   DBSCAN(eps=0.9041, ms=5)    1.545315   -0.023168   \n",
       "1     MNIST-AE16-std               KMeans(k=10)    2.852023    0.211665   \n",
       "2     MNIST-AE32-std   DBSCAN(eps=0.2848, ms=5)    0.227037   -0.200674   \n",
       "3     MNIST-AE32-std               KMeans(k=10)    3.042286    0.343941   \n",
       "4   MNIST-PCA100-std   DBSCAN(eps=9.2670, ms=5)   44.456795    0.371181   \n",
       "5   MNIST-PCA100-std               KMeans(k=10)    4.451275   -0.009193   \n",
       "6    MNIST-PCA16-std   DBSCAN(eps=2.8653, ms=5)    8.185663    0.428244   \n",
       "7    MNIST-PCA16-std               KMeans(k=10)    2.531696    0.104884   \n",
       "8    MNIST-PCA32-std   DBSCAN(eps=4.8487, ms=5)   16.217685    0.484579   \n",
       "9    MNIST-PCA32-std               KMeans(k=10)    3.117630   -0.005042   \n",
       "10   MNIST-PCA64-std   DBSCAN(eps=7.3711, ms=5)   29.290378    0.375980   \n",
       "11   MNIST-PCA64-std               KMeans(k=10)    4.148160    0.018253   \n",
       "12     MNIST-raw-std  DBSCAN(eps=27.4674, ms=5)  103.270871    0.445458   \n",
       "13     MNIST-raw-std               KMeans(k=10)   11.995339    0.008330   \n",
       "\n",
       "    davies_bouldin  calinski_harabasz       NMI       ARI  \n",
       "0         1.899329          59.547901  0.002019  0.000052  \n",
       "1         1.228651       28006.065111  0.173249  0.090348  \n",
       "2         1.734830          76.923319  0.009375  0.000188  \n",
       "3         0.829484       35895.852292  0.169458  0.124190  \n",
       "4         3.205959          64.412320  0.006819  0.000189  \n",
       "5         3.575616         349.860343  0.314552  0.172776  \n",
       "6         2.376834         242.012744  0.002599  0.000078  \n",
       "7         2.000510        2300.084894  0.415973  0.291133  \n",
       "8         2.341554         158.518645  0.004838  0.000140  \n",
       "9         2.916262        1068.014889  0.380821  0.243943  \n",
       "10        3.482298         122.401711  0.006081  0.000153  \n",
       "11        3.571098         518.282279  0.310092  0.143419  \n",
       "12        3.198306          67.918793  0.011832  0.000291  \n",
       "13        3.309745         868.448541  0.429806  0.316979  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expect: X_mnist_scaled, y_mnist, mnist_pca_feats (dict), mnist_ae_latents (dict)\n",
    "mnist_results = []\n",
    "\n",
    "# --- Define feature spaces (all scaled) ---\n",
    "spaces = []\n",
    "# Raw standardized pixels (already scaled)\n",
    "spaces.append((\"MNIST-raw-std\", X_mnist_scaled, \"none\"))\n",
    "\n",
    "# PCA spaces (standardize PCA outputs too)\n",
    "for d, Xp in mnist_pca_feats.items():\n",
    "    spaces.append((f\"MNIST-PCA{d}-std\", stdz(Xp), f\"PCA-{d}\"))\n",
    "\n",
    "# AE spaces (standardize latents)\n",
    "HAS_MNIST_AE = 'mnist_ae_latents' in globals() and isinstance(mnist_ae_latents, dict) and len(mnist_ae_latents) > 0\n",
    "if HAS_MNIST_AE:\n",
    "    for ld, Z in mnist_ae_latents.items():\n",
    "        spaces.append((f\"MNIST-AE{ld}-std\", stdz(Z), f\"AE-{ld}\"))\n",
    "\n",
    "# Small utility to be compatible whether compute_internal_metrics takes sample_size or not\n",
    "def _compute_internal(X, labels, sample_size=8000):\n",
    "    try:\n",
    "        return compute_internal_metrics(X, labels, sample_size=sample_size)\n",
    "    except TypeError:\n",
    "        return compute_internal_metrics(X, labels)\n",
    "\n",
    "# --- 1) KMeans across ALL spaces (k=10), using sampled silhouette internally ---\n",
    "K_DIGITS = 10\n",
    "for name, Xs, tag in spaces:\n",
    "    labels, t = run_kmeans(Xs, k=K_DIGITS, minibatch=False)\n",
    "    m_int = _compute_internal(Xs, labels, sample_size=8000)\n",
    "    m_ext = compute_external_metrics(y_mnist, labels)\n",
    "    mnist_results.append({\n",
    "        \"Feature_Space\": name,\n",
    "        \"Method\": f\"KMeans(k={K_DIGITS})\",\n",
    "        \"Fit_Time_s\": t,\n",
    "        **m_int, **m_ext\n",
    "    })\n",
    "\n",
    "# --- 2) Select TOP-N spaces for DBSCAN via quick KMeans silhouette ranking ---\n",
    "TOP_N_SPACES = 7  # tune to 1–3 depending on time budget\n",
    "spaces_for_selection = [(name, Xs) for name, Xs, _ in spaces]\n",
    "top_spaces = select_spaces_for_dbscan(spaces_for_selection, k=K_DIGITS, top_n=TOP_N_SPACES)\n",
    "print(\"DBSCAN will run on:\", [n for n, _ in top_spaces])\n",
    "\n",
    "# --- 3) Fast DBSCAN on selected spaces: subsampled eps band + 3 trials ---\n",
    "DBSCAN_MIN_SAMPLES = 5\n",
    "SUBSAMPLE_FOR_KNN = 12000  # subsample size for eps band estimation; lower if still slow\n",
    "\n",
    "for name, Xs in top_spaces:\n",
    "    # Estimate a reasonable eps band from subsampled kNN distances\n",
    "    eps_band = guess_eps_from_knn(\n",
    "        Xs, min_samples=DBSCAN_MIN_SAMPLES, subsample=SUBSAMPLE_FOR_KNN,\n",
    "        lo=0.60, hi=0.90, pad=0.10\n",
    "    )\n",
    "    # Try just 3 eps values in that band; pick best by sampled silhouette\n",
    "    best = dbscan_quick(\n",
    "        Xs, min_samples=DBSCAN_MIN_SAMPLES, eps_band=eps_band\n",
    "    )\n",
    "\n",
    "    labels = best[\"labels\"]\n",
    "    m_int = _compute_internal(Xs, labels, sample_size=8000)\n",
    "    m_ext = compute_external_metrics(y_mnist, labels)\n",
    "    mnist_results.append({\n",
    "        \"Feature_Space\": name,\n",
    "        \"Method\": f\"DBSCAN(eps={best['eps']:.4f}, ms={best['min_samples']})\",\n",
    "        \"Fit_Time_s\": best[\"time\"],\n",
    "        **m_int, **m_ext\n",
    "    })\n",
    "\n",
    "# --- 4) Collate results ---\n",
    "mnist_df = pd.DataFrame(mnist_results).sort_values([\"Feature_Space\",\"Method\"]).reset_index(drop=True)\n",
    "mnist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a755002-b258-4b38-9464-9a9ec30b5c5e",
   "metadata": {},
   "source": [
    "MNIST dataset results for raw dataset, 4x PCA sources and 2x AE sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f273b01-8fef-4bfd-9ad3-137acff0b302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Space</th>\n",
       "      <th>Method</th>\n",
       "      <th>Fit_Time_s</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>davies_bouldin</th>\n",
       "      <th>calinski_harabasz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUST-AE-std</td>\n",
       "      <td>DBSCAN(eps=0.4991, ms=5)</td>\n",
       "      <td>0.013876</td>\n",
       "      <td>0.449455</td>\n",
       "      <td>4.063197</td>\n",
       "      <td>63.617355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUST-AE-std</td>\n",
       "      <td>KMeans(k=4)</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.500449</td>\n",
       "      <td>0.650165</td>\n",
       "      <td>273.215101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUST-PCA2-std</td>\n",
       "      <td>DBSCAN(eps=0.5973, ms=5)</td>\n",
       "      <td>0.012239</td>\n",
       "      <td>0.419346</td>\n",
       "      <td>0.696415</td>\n",
       "      <td>9.119516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUST-PCA2-std</td>\n",
       "      <td>KMeans(k=4)</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.428790</td>\n",
       "      <td>0.771582</td>\n",
       "      <td>174.265485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUST-PCA3-std</td>\n",
       "      <td>DBSCAN(eps=0.6846, ms=5)</td>\n",
       "      <td>0.013911</td>\n",
       "      <td>0.274444</td>\n",
       "      <td>3.298704</td>\n",
       "      <td>7.547677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CUST-PCA3-std</td>\n",
       "      <td>KMeans(k=6)</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.431333</td>\n",
       "      <td>0.812192</td>\n",
       "      <td>122.113054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CUST-raw-std</td>\n",
       "      <td>DBSCAN(eps=1.1732, ms=5)</td>\n",
       "      <td>0.014155</td>\n",
       "      <td>0.303870</td>\n",
       "      <td>0.512926</td>\n",
       "      <td>3.382557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CUST-raw-std</td>\n",
       "      <td>KMeans(k=6)</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.356486</td>\n",
       "      <td>1.005090</td>\n",
       "      <td>99.654879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_Space                    Method  Fit_Time_s  silhouette  \\\n",
       "0    CUST-AE-std  DBSCAN(eps=0.4991, ms=5)    0.013876    0.449455   \n",
       "1    CUST-AE-std               KMeans(k=4)    0.004134    0.500449   \n",
       "2  CUST-PCA2-std  DBSCAN(eps=0.5973, ms=5)    0.012239    0.419346   \n",
       "3  CUST-PCA2-std               KMeans(k=4)    0.003226    0.428790   \n",
       "4  CUST-PCA3-std  DBSCAN(eps=0.6846, ms=5)    0.013911    0.274444   \n",
       "5  CUST-PCA3-std               KMeans(k=6)    0.003557    0.431333   \n",
       "6   CUST-raw-std  DBSCAN(eps=1.1732, ms=5)    0.014155    0.303870   \n",
       "7   CUST-raw-std               KMeans(k=6)    0.006072    0.356486   \n",
       "\n",
       "   davies_bouldin  calinski_harabasz  \n",
       "0        4.063197          63.617355  \n",
       "1        0.650165         273.215101  \n",
       "2        0.696415           9.119516  \n",
       "3        0.771582         174.265485  \n",
       "4        3.298704           7.547677  \n",
       "5        0.812192         122.113054  \n",
       "6        0.512926           3.382557  \n",
       "7        1.005090          99.654879  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expect: X_cust, cust_pca_feats (dict), and optionally Z_cust from your tabular AE\n",
    "\n",
    "cust_results = []\n",
    "\n",
    "# --- Define spaces (all scaled) ---\n",
    "cust_spaces = [(\"CUST-raw-std\", X_cust, \"none\")]  # X_cust is already standardized post-OHE\n",
    "\n",
    "for d, Xp in cust_pca_feats.items():\n",
    "    cust_spaces.append((f\"CUST-PCA{d}-std\", stdz(Xp), f\"PCA-{d}\"))\n",
    "\n",
    "HAS_CUST_AE = 'Z_cust' in globals()\n",
    "if HAS_CUST_AE:\n",
    "    cust_spaces.append((f\"CUST-AE-std\", stdz(Z_cust), \"AE\"))\n",
    "\n",
    "# --- Compatibility wrappers (handles both \"sample_size\" and no-arg variants) ---\n",
    "def _silhouette(X, labels, sample=1000):\n",
    "    try:\n",
    "        return safe_silhouette(X, labels, sample_size=min(sample, len(X)))\n",
    "    except TypeError:\n",
    "        return safe_silhouette(X, labels)\n",
    "\n",
    "def _compute_internal(X, labels, sample=1000):\n",
    "    try:\n",
    "        return compute_internal_metrics(X, labels, sample_size=min(sample, len(X)))\n",
    "    except TypeError:\n",
    "        return compute_internal_metrics(X, labels)\n",
    "\n",
    "# --- KMeans: choose k by sampled silhouette (2..10) ---\n",
    "def best_k_by_silhouette(X, k_range=range(2, 11), sample=1000):\n",
    "    best_k, best_sil, best_labels, best_time = None, -np.inf, None, np.nan\n",
    "    for k in k_range:\n",
    "        labels, t = run_kmeans(X, k=k, minibatch=False)\n",
    "        sil = _silhouette(X, labels, sample=sample)\n",
    "        score = -np.inf if (isinstance(sil, float) and np.isnan(sil)) else sil\n",
    "        if score > best_sil:\n",
    "            best_k, best_sil, best_labels, best_time = k, sil, labels, t\n",
    "    return best_k, best_labels, best_time, best_sil\n",
    "\n",
    "# --- Run KMeans on all customer subspaces ---\n",
    "for name, Xs, tag in cust_spaces:\n",
    "    k, labels, t, sil = best_k_by_silhouette(Xs, range(2, 11), sample=1000)\n",
    "    m_int = _compute_internal(Xs, labels, sample=1000)\n",
    "    cust_results.append({\n",
    "        \"Feature_Space\": name,\n",
    "        \"Method\": f\"KMeans(k={k})\",\n",
    "        \"Fit_Time_s\": t,\n",
    "        **m_int  # no external metrics (no ground truth)\n",
    "    })\n",
    "\n",
    "# --- DBSCAN on ALL subspaces (fast eps-band + 3 trials) ---\n",
    "DBSCAN_MIN_SAMPLES = 5\n",
    "SUBSAMPLE_FOR_KNN  = min(2000, len(X_cust))  # tiny dataset → small subsample is fine\n",
    "\n",
    "for name, Xs, tag in cust_spaces:\n",
    "    # 1) Estimate eps band from a subsample (cheap and robust)\n",
    "    eps_lo, eps_hi = guess_eps_from_knn(\n",
    "        Xs, min_samples=DBSCAN_MIN_SAMPLES,\n",
    "        subsample=SUBSAMPLE_FOR_KNN, lo=0.60, hi=0.90, pad=0.10\n",
    "    )\n",
    "    # 2) Try 3 eps values in that band; keep best by sampled silhouette\n",
    "    best = dbscan_quick(\n",
    "        Xs, min_samples=DBSCAN_MIN_SAMPLES, eps_band=(eps_lo, eps_hi)\n",
    "    )\n",
    "\n",
    "    labels = best[\"labels\"]\n",
    "    m_int = _compute_internal(Xs, labels, sample=1000)\n",
    "    cust_results.append({\n",
    "        \"Feature_Space\": name,\n",
    "        \"Method\": f\"DBSCAN(eps={best['eps']:.4f}, ms={best['min_samples']})\",\n",
    "        \"Fit_Time_s\": best[\"time\"],\n",
    "        **m_int\n",
    "    })\n",
    "\n",
    "cust_df = pd.DataFrame(cust_results).sort_values([\"Feature_Space\",\"Method\"]).reset_index(drop=True)\n",
    "cust_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a45656-cfdc-4930-b9dd-c5f8e9e7eba0",
   "metadata": {},
   "source": [
    "Customer dataset results for raw dataset, 2x PCA sources and 1x AE source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ee126-3763-4b17-b5a9-a399123cacbb",
   "metadata": {},
   "source": [
    "### Final Output Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "44937780-1158-44ec-9326-fede9d5bcdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Space</th>\n",
       "      <th>Method</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>NMI</th>\n",
       "      <th>ARI</th>\n",
       "      <th>davies_bouldin</th>\n",
       "      <th>calinski_harabasz</th>\n",
       "      <th>Fit_Time_s</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNIST-PCA16-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.291</td>\n",
       "      <td>2.001</td>\n",
       "      <td>2300.1</td>\n",
       "      <td>2.532</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNIST-raw-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.317</td>\n",
       "      <td>3.310</td>\n",
       "      <td>868.4</td>\n",
       "      <td>11.995</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNIST-PCA32-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.244</td>\n",
       "      <td>2.916</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>3.118</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNIST-raw-std</td>\n",
       "      <td>DBSCAN(eps=27.4674, ms=5)</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.198</td>\n",
       "      <td>67.9</td>\n",
       "      <td>103.271</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNIST-AE32-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.829</td>\n",
       "      <td>35895.9</td>\n",
       "      <td>3.042</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MNIST-PCA64-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.143</td>\n",
       "      <td>3.571</td>\n",
       "      <td>518.3</td>\n",
       "      <td>4.148</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MNIST-AE16-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.090</td>\n",
       "      <td>1.229</td>\n",
       "      <td>28006.1</td>\n",
       "      <td>2.852</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MNIST-PCA100-std</td>\n",
       "      <td>KMeans(k=10)</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.173</td>\n",
       "      <td>3.576</td>\n",
       "      <td>349.9</td>\n",
       "      <td>4.451</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MNIST-PCA100-std</td>\n",
       "      <td>DBSCAN(eps=9.2670, ms=5)</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.206</td>\n",
       "      <td>64.4</td>\n",
       "      <td>44.457</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MNIST-PCA32-std</td>\n",
       "      <td>DBSCAN(eps=4.8487, ms=5)</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.342</td>\n",
       "      <td>158.5</td>\n",
       "      <td>16.218</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MNIST-PCA64-std</td>\n",
       "      <td>DBSCAN(eps=7.3711, ms=5)</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.482</td>\n",
       "      <td>122.4</td>\n",
       "      <td>29.290</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MNIST-PCA16-std</td>\n",
       "      <td>DBSCAN(eps=2.8653, ms=5)</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.377</td>\n",
       "      <td>242.0</td>\n",
       "      <td>8.186</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MNIST-AE32-std</td>\n",
       "      <td>DBSCAN(eps=0.2848, ms=5)</td>\n",
       "      <td>-0.201</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.735</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.227</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MNIST-AE16-std</td>\n",
       "      <td>DBSCAN(eps=0.9041, ms=5)</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.899</td>\n",
       "      <td>59.5</td>\n",
       "      <td>1.545</td>\n",
       "      <td>13.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature_Space                     Method  silhouette    NMI    ARI  \\\n",
       "0    MNIST-PCA16-std               KMeans(k=10)       0.105  0.416  0.291   \n",
       "1      MNIST-raw-std               KMeans(k=10)       0.008  0.430  0.317   \n",
       "2    MNIST-PCA32-std               KMeans(k=10)      -0.005  0.381  0.244   \n",
       "3      MNIST-raw-std  DBSCAN(eps=27.4674, ms=5)       0.445  0.012  0.000   \n",
       "4     MNIST-AE32-std               KMeans(k=10)       0.344  0.169  0.124   \n",
       "5    MNIST-PCA64-std               KMeans(k=10)       0.018  0.310  0.143   \n",
       "6     MNIST-AE16-std               KMeans(k=10)       0.212  0.173  0.090   \n",
       "7   MNIST-PCA100-std               KMeans(k=10)      -0.009  0.315  0.173   \n",
       "8   MNIST-PCA100-std   DBSCAN(eps=9.2670, ms=5)       0.371  0.007  0.000   \n",
       "9    MNIST-PCA32-std   DBSCAN(eps=4.8487, ms=5)       0.485  0.005  0.000   \n",
       "10   MNIST-PCA64-std   DBSCAN(eps=7.3711, ms=5)       0.376  0.006  0.000   \n",
       "11   MNIST-PCA16-std   DBSCAN(eps=2.8653, ms=5)       0.428  0.003  0.000   \n",
       "12    MNIST-AE32-std   DBSCAN(eps=0.2848, ms=5)      -0.201  0.009  0.000   \n",
       "13    MNIST-AE16-std   DBSCAN(eps=0.9041, ms=5)      -0.023  0.002  0.000   \n",
       "\n",
       "    davies_bouldin  calinski_harabasz  Fit_Time_s  Score  \n",
       "0            2.001             2300.1       2.532    4.0  \n",
       "1            3.310              868.4      11.995    4.0  \n",
       "2            2.916             1068.0       3.118    5.7  \n",
       "3            3.198               67.9     103.271    6.0  \n",
       "4            0.829            35895.9       3.042    6.3  \n",
       "5            3.571              518.3       4.148    6.3  \n",
       "6            1.229            28006.1       2.852    6.7  \n",
       "7            3.576              349.9       4.451    6.7  \n",
       "8            3.206               64.4      44.457    8.0  \n",
       "9            2.342              158.5      16.218    8.3  \n",
       "10           3.482              122.4      29.290    8.7  \n",
       "11           2.377              242.0       8.186    9.7  \n",
       "12           1.735               76.9       0.227   11.0  \n",
       "13           1.899               59.5       1.545   13.7  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Safety: ensure expected columns exist even if missing in your df ---\n",
    "def ensure_cols(df, cols):\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        if c not in out.columns:\n",
    "            out[c] = np.nan\n",
    "    return out\n",
    "\n",
    "# Build MNIST table with ranks and an overall score\n",
    "_mnist = ensure_cols(\n",
    "    mnist_df,\n",
    "    [\"Feature_Space\",\"Method\",\"silhouette\",\"NMI\",\"ARI\",\"davies_bouldin\",\"calinski_harabasz\",\"Fit_Time_s\"]\n",
    ").copy()\n",
    "\n",
    "# Ranks (smaller DB is better; larger is better for others)\n",
    "_mnist[\"Rank_Sil\"] = _mnist[\"silhouette\"].rank(ascending=False, method=\"min\")\n",
    "_mnist[\"Rank_NMI\"] = _mnist[\"NMI\"].rank(ascending=False, method=\"min\")\n",
    "_mnist[\"Rank_ARI\"] = _mnist[\"ARI\"].rank(ascending=False, method=\"min\")\n",
    "_mnist[\"Rank_DB\"]  = _mnist[\"davies_bouldin\"].rank(ascending=True,  method=\"min\")\n",
    "_mnist[\"Rank_CH\"]  = _mnist[\"calinski_harabasz\"].rank(ascending=False, method=\"min\")\n",
    "\n",
    "# Overall score (only metrics with ground truth get in the score)\n",
    "_mnist[\"Score\"] = (_mnist[\"Rank_Sil\"] + _mnist[\"Rank_NMI\"] + _mnist[\"Rank_ARI\"]) / 3.0\n",
    "\n",
    "mnist_table = (\n",
    "    _mnist\n",
    "    .sort_values([\"Score\",\"Rank_Sil\",\"Rank_DB\"], ascending=[True, True, True])\n",
    "    [[\"Feature_Space\",\"Method\",\"silhouette\",\"NMI\",\"ARI\",\"davies_bouldin\",\"calinski_harabasz\",\"Fit_Time_s\",\"Score\"]]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Round for readability\n",
    "mnist_table = mnist_table.round({\n",
    "    \"silhouette\": 3, \"NMI\": 3, \"ARI\": 3,\n",
    "    \"davies_bouldin\": 3, \"calinski_harabasz\": 1, \"Fit_Time_s\": 3, \"Score\": 1\n",
    "})\n",
    "\n",
    "mnist_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "336b90d1-185f-4e1f-8ec1-5d0aa86c167d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_Space</th>\n",
       "      <th>Method</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>davies_bouldin</th>\n",
       "      <th>calinski_harabasz</th>\n",
       "      <th>Fit_Time_s</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CUST-AE-std</td>\n",
       "      <td>KMeans(k=4)</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.650</td>\n",
       "      <td>273.2</td>\n",
       "      <td>0.004</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CUST-PCA2-std</td>\n",
       "      <td>KMeans(k=4)</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.772</td>\n",
       "      <td>174.3</td>\n",
       "      <td>0.003</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CUST-PCA3-std</td>\n",
       "      <td>KMeans(k=6)</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.812</td>\n",
       "      <td>122.1</td>\n",
       "      <td>0.004</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CUST-PCA2-std</td>\n",
       "      <td>DBSCAN(eps=0.5973, ms=5)</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.696</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.012</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CUST-AE-std</td>\n",
       "      <td>DBSCAN(eps=0.4991, ms=5)</td>\n",
       "      <td>0.449</td>\n",
       "      <td>4.063</td>\n",
       "      <td>63.6</td>\n",
       "      <td>0.014</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CUST-raw-std</td>\n",
       "      <td>KMeans(k=6)</td>\n",
       "      <td>0.356</td>\n",
       "      <td>1.005</td>\n",
       "      <td>99.7</td>\n",
       "      <td>0.006</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CUST-raw-std</td>\n",
       "      <td>DBSCAN(eps=1.1732, ms=5)</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.513</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.014</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CUST-PCA3-std</td>\n",
       "      <td>DBSCAN(eps=0.6846, ms=5)</td>\n",
       "      <td>0.274</td>\n",
       "      <td>3.299</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.014</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature_Space                    Method  silhouette  davies_bouldin  \\\n",
       "0    CUST-AE-std               KMeans(k=4)       0.500           0.650   \n",
       "1  CUST-PCA2-std               KMeans(k=4)       0.429           0.772   \n",
       "2  CUST-PCA3-std               KMeans(k=6)       0.431           0.812   \n",
       "3  CUST-PCA2-std  DBSCAN(eps=0.5973, ms=5)       0.419           0.696   \n",
       "4    CUST-AE-std  DBSCAN(eps=0.4991, ms=5)       0.449           4.063   \n",
       "5   CUST-raw-std               KMeans(k=6)       0.356           1.005   \n",
       "6   CUST-raw-std  DBSCAN(eps=1.1732, ms=5)       0.304           0.513   \n",
       "7  CUST-PCA3-std  DBSCAN(eps=0.6846, ms=5)       0.274           3.299   \n",
       "\n",
       "   calinski_harabasz  Fit_Time_s  Score  \n",
       "0              273.2       0.004    1.3  \n",
       "1              174.3       0.003    3.3  \n",
       "2              122.1       0.004    3.7  \n",
       "3                9.1       0.012    4.7  \n",
       "4               63.6       0.014    5.0  \n",
       "5               99.7       0.006    5.3  \n",
       "6                3.4       0.014    5.3  \n",
       "7                7.5       0.014    7.3  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure columns exist\n",
    "_cust = ensure_cols(\n",
    "    cust_df,\n",
    "    [\"Feature_Space\",\"Method\",\"silhouette\",\"davies_bouldin\",\"calinski_harabasz\",\"Fit_Time_s\"]\n",
    ").copy()\n",
    "\n",
    "# Ranks (no external metrics here)\n",
    "_cust[\"Rank_Sil\"] = _cust[\"silhouette\"].rank(ascending=False, method=\"min\")\n",
    "_cust[\"Rank_DB\"]  = _cust[\"davies_bouldin\"].rank(ascending=True,  method=\"min\")\n",
    "_cust[\"Rank_CH\"]  = _cust[\"calinski_harabasz\"].rank(ascending=False, method=\"min\")\n",
    "\n",
    "# Simple combined score from internal metrics\n",
    "_cust[\"Score\"] = (_cust[\"Rank_Sil\"] + _cust[\"Rank_DB\"] + _cust[\"Rank_CH\"]) / 3.0\n",
    "\n",
    "cust_table = (\n",
    "    _cust\n",
    "    .sort_values([\"Score\",\"Rank_Sil\",\"Rank_DB\"], ascending=[True, True, True])\n",
    "    [[\"Feature_Space\",\"Method\",\"silhouette\",\"davies_bouldin\",\"calinski_harabasz\",\"Fit_Time_s\",\"Score\"]]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "cust_table = cust_table.round({\n",
    "    \"silhouette\": 3, \"davies_bouldin\": 3, \"calinski_harabasz\": 1, \"Fit_Time_s\": 3, \"Score\": 1\n",
    "})\n",
    "\n",
    "cust_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:research_disc_one_env]",
   "language": "python",
   "name": "conda-env-research_disc_one_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
